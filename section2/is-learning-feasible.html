<!DOCTYPE HTML>
<html lang="en-US" manifest="../manifest.appcache">
    
    <head>
        
        <meta charset="UTF-8">
        <title>机器学习的可行性 | 机器学习笔记</title>
        <meta content="text/html; charset=utf-8" http-equiv="Content-Type">
        <meta name="description" content="">
        <meta name="generator" content="GitBook 0.7.1">
        <meta name="HandheldFriendly" content="true"/>
        <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">
        <meta name="apple-mobile-web-app-capable" content="yes">
        <meta name="apple-mobile-web-app-status-bar-style" content="black">
        <link rel="shortcut icon" href="../gitbook/images/favicon.ico" type="image/x-icon">
        
    
    
    <meta name="author" content="beader">
    
    
    <link rel="next" href="../section2/vc-dimension-one.html" />
    
    
    <link rel="prev" href="../section2/README.html" />
    

        
    </head>
    <body>
        
        
<link rel="stylesheet" href="../gitbook/style.css">


        
    <div class="book" data-github="beader/mlnotebook" data-level="2.1" data-basepath=".." data-revision="1409033329936">
    <div class="book-header">
    <!-- Actions Left -->
    <a href="#" class="btn pull-left toggle-summary" aria-label="Toggle summary"><i class="fa fa-align-justify"></i></a>
    
    <a href="https://github.com/beader/mlnotebook" target="_blank" class="btn pull-left home-bookmark" aria-label="GitHub home"><i class="fa fa-bookmark-o"></i></a>
    
    <a href="#" class="btn pull-left toggle-search" aria-label="Toggle search"><i class="fa fa-search"></i></a>
    <span id="font-settings-wrapper">
        <a href="#" class="btn pull-left toggle-font-settings" aria-label="Toggle font settings"><i class="fa fa-font"></i>
        </a>
        <div class="dropdown-menu font-settings">
    <div class="dropdown-caret">
        <span class="caret-outer"></span>
        <span class="caret-inner"></span>
    </div>

    <div class="btn-group btn-block">
        <button id="reduce-font-size" class="btn btn-default">A</button>
        <button id="enlarge-font-size" class="btn btn-default">A</button>
    </div>

    <ul class="list-group font-family-list">
        <li class="list-group-item" data-font="0">Serif</li>
        <li class="list-group-item" data-font="1">Sans</li>
    </ul>

    <div class="btn-group btn-group-xs btn-block color-theme-list">
        <button type="button" class="btn btn-default" id="color-theme-preview-0" data-theme="0">White</button>
        <button type="button" class="btn btn-default" id="color-theme-preview-1" data-theme="1">Sepia</button>
        <button type="button" class="btn btn-default" id="color-theme-preview-2" data-theme="2">Night</button>
    </div>
</div>

    </span>

    <!-- Actions Right -->
    
    <a href="#" target="_blank" class="btn pull-right google-plus-sharing-link sharing-link" data-sharing="google-plus" aria-label="Share on Google Plus"><i class="fa fa-google-plus"></i></a>
    
    
    <a href="#" target="_blank" class="btn pull-right facebook-sharing-link sharing-link" data-sharing="facebook" aria-label="Share on Facebook"><i class="fa fa-facebook"></i></a>
    
    
    <a href="#" target="_blank" class="btn pull-right twitter-sharing-link sharing-link" data-sharing="twitter" aria-label="Share on Twitter"><i class="fa fa-twitter"></i></a>
    
    

    <!-- Title -->
    <h1>
        <i class="fa fa-spinner fa-spin"></i>
        <a href="../" >机器学习笔记</a>
    </h1>
</div>

    

<div class="book-summary">
    <div class="book-search">
        <input type="text" placeholder="Search" class="form-control" />
    </div>
    <ul class="summary">
        
        
        
        <li>
            <a href="https://github.com/beader" target="blank" class="author-link">About the author</a>
        </li>
        

        
        
        <li>
            <a href="https://github.com/beader/mlnotebook/issues" target="blank" class="issues-link">Questions and Issues</a>
        </li>
        

        
        
        <li>
            <a href="https://github.com/beader/mlnotebook/edit/master/section2/is-learning-feasible.md" target="blank" class="contribute-link">Edit and Contribute</a>
        </li>
        

	

        
        <li class="divider"></li>
        

        
    
        
        <li class="chapter " data-level="0" data-path="index.html">
            
                
                    <a href="../index.html">
                        <i class="fa fa-check"></i>
                        
                         Introduction
                    </a>
                
            
            
        </li>
    
        
        <li class="chapter " data-level="1" data-path="section1/README.html">
            
                
                    <a href="../section1/README.html">
                        <i class="fa fa-check"></i>
                        
                            <b>1.</b>
                        
                         When Can Machines Learn?
                    </a>
                
            
            
        </li>
    
        
        <li class="chapter " data-level="2" data-path="section2/README.html">
            
                
                    <a href="../section2/README.html">
                        <i class="fa fa-check"></i>
                        
                            <b>2.</b>
                        
                         Why Can Machines Learn?
                    </a>
                
            
            
            <ul class="articles">
                
    
        
        <li class="chapter active" data-level="2.1" data-path="section2/is-learning-feasible.html">
            
                
                    <a href="../section2/is-learning-feasible.html">
                        <i class="fa fa-check"></i>
                        
                            <b>2.1.</b>
                        
                         机器学习的可行性
                    </a>
                
            
            
        </li>
    
        
        <li class="chapter " data-level="2.2" data-path="section2/vc-dimension-one.html">
            
                
                    <a href="../section2/vc-dimension-one.html">
                        <i class="fa fa-check"></i>
                        
                            <b>2.2.</b>
                        
                         VC Dimension Part I
                    </a>
                
            
            
        </li>
    
        
        <li class="chapter " data-level="2.3" data-path="section2/vc-dimension-two.html">
            
                
                    <a href="../section2/vc-dimension-two.html">
                        <i class="fa fa-check"></i>
                        
                            <b>2.3.</b>
                        
                         VC Dimension Part II
                    </a>
                
            
            
        </li>
    
        
        <li class="chapter " data-level="2.4" data-path="section2/vc-dimension-three.html">
            
                
                    <a href="../section2/vc-dimension-three.html">
                        <i class="fa fa-check"></i>
                        
                            <b>2.4.</b>
                        
                         VC Dimension Part III
                    </a>
                
            
            
        </li>
    
        
        <li class="chapter " data-level="2.5" data-path="section2/noise-and-error.html">
            
                
                    <a href="../section2/noise-and-error.html">
                        <i class="fa fa-check"></i>
                        
                            <b>2.5.</b>
                        
                         Noise and Error
                    </a>
                
            
            
        </li>
    

            </ul>
            
        </li>
    
        
        <li class="chapter " data-level="3" data-path="section3/README.html">
            
                
                    <a href="../section3/README.html">
                        <i class="fa fa-check"></i>
                        
                            <b>3.</b>
                        
                         How Can Machines Learn?
                    </a>
                
            
            
            <ul class="articles">
                
    
        
        <li class="chapter " data-level="3.1" data-path="section3/linear-regression.html">
            
                
                    <a href="../section3/linear-regression.html">
                        <i class="fa fa-check"></i>
                        
                            <b>3.1.</b>
                        
                         Linear Regression
                    </a>
                
            
            
        </li>
    
        
        <li class="chapter " data-level="3.2" data-path="section3/logistic-regression.html">
            
                
                    <a href="../section3/logistic-regression.html">
                        <i class="fa fa-check"></i>
                        
                            <b>3.2.</b>
                        
                         Logistic Regression
                    </a>
                
            
            
        </li>
    
        
        <li class="chapter " data-level="3.3" data-path="section3/linear_models_for_classification.html">
            
                
                    <a href="../section3/linear_models_for_classification.html">
                        <i class="fa fa-check"></i>
                        
                            <b>3.3.</b>
                        
                         Linear Models for Classification
                    </a>
                
            
            
        </li>
    

            </ul>
            
        </li>
    
        
        <li class="chapter " data-level="4" data-path="section4/README.html">
            
                
                    <a href="../section4/README.html">
                        <i class="fa fa-check"></i>
                        
                            <b>4.</b>
                        
                         How Can Machines Learn Better?
                    </a>
                
            
            
        </li>
    
        
        <li class="chapter " data-level="5" data-path="section5/README.html">
            
                
                    <a href="../section5/README.html">
                        <i class="fa fa-check"></i>
                        
                            <b>5.</b>
                        
                         FAQ
                    </a>
                
            
            
        </li>
    


        
        <li class="divider"></li>
        <li>
            <a href="http://www.gitbook.io/" target="blank" class="gitbook-link">Generated using GitBook</a>
        </li>
        
    </ul>
</div>

    <div class="book-body">
        <div class="body-inner">
            <div class="page-wrapper" tabindex="-1">
                <div class="book-progress">
    <div class="bar">
        <div class="inner" style="width: 23.076923076923077%;min-width: 15.384615384615385%;"></div>
    </div>
    <div class="chapters">
    
        <a href="../index.html" title="Introduction" class="chapter done new-chapter" data-progress="0" style="left: 0%;"></a>
    
        <a href="../section1/README.html" title="When Can Machines Learn?" class="chapter done new-chapter" data-progress="1" style="left: 7.6923076923076925%;"></a>
    
        <a href="../section2/README.html" title="Why Can Machines Learn?" class="chapter done new-chapter" data-progress="2" style="left: 15.384615384615385%;"></a>
    
        <a href="../section2/is-learning-feasible.html" title="机器学习的可行性" class="chapter done " data-progress="2.1" style="left: 23.076923076923077%;"></a>
    
        <a href="../section2/vc-dimension-one.html" title="VC Dimension Part I" class="chapter  " data-progress="2.2" style="left: 30.76923076923077%;"></a>
    
        <a href="../section2/vc-dimension-two.html" title="VC Dimension Part II" class="chapter  " data-progress="2.3" style="left: 38.46153846153846%;"></a>
    
        <a href="../section2/vc-dimension-three.html" title="VC Dimension Part III" class="chapter  " data-progress="2.4" style="left: 46.15384615384615%;"></a>
    
        <a href="../section2/noise-and-error.html" title="Noise and Error" class="chapter  " data-progress="2.5" style="left: 53.84615384615385%;"></a>
    
        <a href="../section3/README.html" title="How Can Machines Learn?" class="chapter  new-chapter" data-progress="3" style="left: 61.53846153846154%;"></a>
    
        <a href="../section3/linear-regression.html" title="Linear Regression" class="chapter  " data-progress="3.1" style="left: 69.23076923076923%;"></a>
    
        <a href="../section3/logistic-regression.html" title="Logistic Regression" class="chapter  " data-progress="3.2" style="left: 76.92307692307692%;"></a>
    
        <a href="../section3/linear_models_for_classification.html" title="Linear Models for Classification" class="chapter  " data-progress="3.3" style="left: 84.61538461538461%;"></a>
    
        <a href="../section4/README.html" title="How Can Machines Learn Better?" class="chapter  new-chapter" data-progress="4" style="left: 92.3076923076923%;"></a>
    
        <a href="../section5/README.html" title="FAQ" class="chapter  new-chapter" data-progress="5" style="left: 100%;"></a>
    
    </div>
</div>

                <div class="page-inner">
                
                    <section class="normal" id="section-gitbook_4">
                    
                        <h2 id="-learning-from-data">机器学习的基础架构 (Learning From Data)</h2>
<p>&emsp;&emsp;银行在决定是否要通过贷款申请人的授信请求前，会根据申请人的资料对其进行风险评估，(通常银行会为其计算信用评分)，申请人状况符合银行要求时，银行通过其申请，反之则婉拒。那么银行凭借什么来判断申请人将来是否会违约呢？通过银行之前的信用贷款记录，这些记录中，有些客户发生了违约行为，其他则表现良好，银行从这些违约与非违约的记录中learning到了一些规律，然后利用这些规律，来对新申请人的违约风险进行估计。因此信用评估模型就是一个learning的问题，那么我们该如何使用历史数据做好learning呢？</p>
<p>&emsp;&emsp;下面这张图描述了learning的基础架构：</p>
<p><img src="images/basic_setup_of_the _learning_problem.png" alt=""></p>
<ul>
<li><p><script type="math/tex">f:\mathcal{X} \to \mathcal{Y}</script>，其中<script type="math/tex">\mathcal{X}</script>表示输入空间，譬如下图中第一列</p>
<p> <code>(age, gender, annual salary, year in residence, year in job, current debt)</code></p>
<p> 为输入空间(6维)，而右边一列</p>
<p> <code>(23 years, female, NTD 1,000,000, 1 year, 0.5 year, 200,000)</code></p>
<p> 为该输入空间下的一个向量，每位贷款申请人对应该空间下的一个向量。
<img src="images/feature_vector.png" alt="">
 <script type="math/tex">\mathcal{Y}</script>表示输出空间，在二元分类中，输出空间是一个1维的取值为+1或-1的空间 <script type="math/tex">\\{-1,+1\\}^1</script>，可以用-1表示非违约，+1表示违约。
 <script type="math/tex">f</script>是未知的真理，是事物运转的规律，假如我们可以拥有<script type="math/tex">f</script>，我们就可以知道一个人到底会不会发生违约行为。但是这个<script type="math/tex">f</script>是不可知的，我们无法窥探其中运行的原理(函数内部构造)，我们唯一知道的是<script type="math/tex">f</script>在我们已知的历史数据<script type="math/tex">\mathcal{D}</script>当中的运行情况(把<script type="math/tex">x_n</script>当做<script type="math/tex">f</script>输入，把<script type="math/tex">y_n</script>当做<script type="math/tex">f</script>的输出)，learning要作的事情，就是找一个在<script type="math/tex">\mathcal{D}</script>中运行情况与<script type="math/tex">f</script>类似的函数，这个函数对于相同的输入，会有与<script type="math/tex">f</script>相同的输出，并且希望在<script type="math/tex">\mathcal{D}</script>之外，也就是我们未知的世界，我们找的这个函数的运行情况还能与<script type="math/tex">f</script>接近。</p>
</li>
</ul>
<ul>
<li><script type="math/tex">\mathcal{D}:(x_1,y_1), \dotsb,(x_N,y_N)</script>为训练集，该训练集有N笔数据，每笔数据由某申请人在<script type="math/tex">\mathcal{X}</script>中的向量和与其对应的类别构成。</li>
<li><p><script type="math/tex">\mathcal{H}</script>，hypothesis set是一个由有限个或无限个方程组成的集合，算法<script type="math/tex">\mathcal{A}</script>只能从<script type="math/tex">\mathcal{H}</script>的范围内挑选方程。</p>
</li>
<li><p><script type="math/tex">\mathcal{A}</script>，是一个学习算法，它能够帮助我们在<script type="math/tex">\mathcal{H}</script>中找到一个与<script type="math/tex">f</script>的判断最接近或足够接近的一个方程。当然我们可以说穷举法是一种学习算法，当<script type="math/tex">\mathcal{H}</script>当中candidate formula数量不多时，我们可以用穷举法来寻找。但往往candidate formula数量很大甚至是无穷的，我们就需要设计一个比较好的算法，他能够在较短时间找到我们想要的那个方程。</p>
</li>
<li><p><script type="math/tex">g</script>，final hypothesis，即<script type="math/tex">\mathcal{A}</script>从<script type="math/tex">\mathcal{H}</script>中挑选的和<script type="math/tex">f</script>判断最接近的那个方程。</p>
</li>
</ul>
<p>&emsp;&emsp;说到底，learning在干的事情，就是从hypothesis set里面挑一个“长”的最像<script type="math/tex">f</script>的方程<script type="math/tex">g</script>，注意前面我的用词是用&quot;它的判断接近<script type="math/tex">f</script>&quot;，并不是说<script type="math/tex">g</script>和<script type="math/tex">f</script>结构很类似，(记住<script type="math/tex">f</script>永远是unknown的)，而是说他们的判断很一致，即<script type="math/tex">f(x)\approx g(x)</script>。并且这里谈到的接近，是针对训练集<script type="math/tex">\mathcal{D}</script>而言的，<script type="math/tex">\mathcal{D}</script>之外的数据他们能否表现一致，这才是我们最应该关心的问题，如果<script type="math/tex">\mathcal{D}</script>之外他们也能够表现一致，说明我们learning的还不错，我们有从<script type="math/tex">\mathcal{D}</script>上面学到东西。这时候换个角度来想，能不能有某个理论，来保证我们的<script type="math/tex">g</script>与<script type="math/tex">f</script>在<script type="math/tex">\mathcal{D}</script>之外也能有差不多的接近程度？</p>
<h2 id="learning-is-learning-feasible">Learning真的可行吗？ (Is Learning Feasible?)</h2>
<p><img src="images/a_learning_puzzle.png" alt=""></p>
<p>&emsp;&emsp;图片前两行为training set，对于第一行的所有样本，有<script type="math/tex">f(x)=-1</script>，对于第二行的所有样本，有<script type="math/tex">f(x)=+1</script>，那么我们能不能通过这6笔数据来猜测一下<script type="math/tex">f</script>是长什么样的呢？同学1和同学2利用各自的学习方法分别给出了自己的<script type="math/tex">g</script> </p>
<ul>
<li>同学1训练出来的g：
<script type="math/tex">g_1(对称图形)=+1</script>
<script type="math/tex">g_1(非对称图形)=-1</script></li>
<li>同学2训练出来的g：
<script type="math/tex">g_2(左上角为白色的图形)=+1</script>
<script type="math/tex">g_2(左上角为黑色的图形)=-1</script></li>
</ul>
<p>&emsp;&emsp;对于training set中所有样本，有<script type="math/tex">g_1(x)=g_2(x)=f(x)</script>，即两个<script type="math/tex">g_1,g_2</script>与<script type="math/tex">f</script>的表现是一致的，似乎可以认为他们都&quot;学&quot;到了东西，但是对于测试样本来说<script type="math/tex">g_1(x)=+1,g_2(x)=-1</script>。真实的<script type="math/tex">f</script>我们无法知道，如果他们中的某一个人在所有非训练的资料中也和<script type="math/tex">f(x)</script>表现一致，我们才能说他们当中某个人真的学到了东西。但在目前这种情况下，我们无法说同学1学到了东西还是同学2学到了东西。</p>
<p>&emsp;&emsp;让我们再来考虑一个简单的二元分类问题。<script type="math/tex">\mathcal{X}=\\{0,1\\}^3</script>，<script type="math/tex">\mathcal{Y}=\\{\mathrm{o},\times\\}^1</script></p>
<p><img src="images/a_simple_binary_classification_problem.png" alt=""></p>
<p>&emsp;&emsp;为何要举这么简单的例子呢？因为前面我们说到真实的<script type="math/tex">f</script>是我们无法知道的，但在上面这个简单的例子中，我们有办法把所有可能的<script type="math/tex">f</script>全部列举出来。</p>
<p><img src="images/no_free_lunch.png" alt=""></p>
<p>&emsp;&emsp;可能产生这样的<script type="math/tex">\mathcal{D}</script>的<script type="math/tex">f</script>只可能有8种并且只有其中的1个是正确的，这样一来，虽然我们可以保证我们的<script type="math/tex">g</script>在<script type="math/tex">\mathcal{D}</script>上的判断和真实的<script type="math/tex">f</script>一致，但我们无法保证在<script type="math/tex">\mathcal{D}</script>之外也同样如此。那么这里便值得怀疑一下机器学习的可行性，机器学习到底可不可行？</p>
<h2 id="inferring-something-unknown">推断未知的世界(Inferring Something Unknown)</h2>
<p>&emsp;&emsp;我们知道在前面简单版的learning问题中，由于我们无法推断<script type="math/tex">\mathcal{D}</script>之外事情，因此learning不可行。但在其他场景中，我们能否利用<script type="math/tex">\mathcal{D}</script>来推断<script type="math/tex">\mathcal{D}</script>以外的事情呢？在统计推断中，我们可以利用样本的统计量(statistic)来推断总体的参数(parameter)，譬如使用样本均值来估计总体期望。假设你想了解某一批大米(1000包)的平均重量，可以通过随机抽样抽取一定数量的样本(20包)，用这20包大米的平均重量估计这1000包大米的平均重量，虽然二者并不一定会完全相等，但也不会相差太大，并且你的样本量越大，你得到的统计量与参数之间的误差会越小。在这个例子中，未知的980包大米的平均重量与我们知道的20包大米的平均重量是有关联的，因此我们似乎可以通过<script type="math/tex">\mathcal{D}</script>来推断<script type="math/tex">\mathcal{D}</script>之外的东西。下面来一个摸球的例子：</p>
<p><img src="images/bin_sample.png" alt=""></p>
<ul>
<li>bin，即总体，假设<script type="math/tex">P(orange)=\mu</script>，<script type="math/tex">P(green)=1-\mu</script>。但我们无法知道<script type="math/tex">\mu</script>到底多大。</li>
<li>sample，即样本，数量为<script type="math/tex">N</script>，在抽出的<script type="math/tex">N</script>个小球中，orange的比例为<script type="math/tex">\nu</script>，green的比例为<script type="math/tex">1-\nu</script>，数一数就能算出<script type="math/tex">\nu</script></li>
</ul>
<p>&emsp;&emsp;问题来了，这个<script type="math/tex">\nu</script>能不能在一定程度上代表了<script type="math/tex">\mu</script>。也许不能，因为即使bin中orange占多数，也可能发生这样的事情，你抽了10个小球出来但全是green的。但这种事情发生的可能性大吗？不大，并且如果我们有更多的样本(抽出更多的球)，则这种事情发生的可能性会越来越小。在概率论中，可以用<a href="http://en.wikipedia.org/wiki/Hoeffding&#39;s_inequality" target="_blank">Hoeffding&#39;s Inequality</a>来描述上面那件事情的概率：</p>
<script type="math/tex; mode=display">\mathbb{P}[|\nu-\mu|>\epsilon]\leq 2exp(-2\epsilon ^2N)</script><p>&emsp;&emsp;注：<script type="math/tex">\epsilon</script>是我们的容忍度，当<script type="math/tex">\mu</script>与<script type="math/tex">\nu</script>的差别小于容忍度时，我们称<script type="math/tex">\mu</script>与<script type="math/tex">\nu</script>“差不多”(PAC, probably approximately correct)，当<script type="math/tex">\mu</script>与<script type="math/tex">\nu</script>差别大于容忍度时，我们称<script type="math/tex">\mu</script>与<script type="math/tex">\nu</script>&quot;差很多&quot;。“差很多”这件事发生的概率越小越好，最大不会超过右边。</p>
<p>&emsp;&emsp;上面这个不等式中，控制右边数值大小的只有<script type="math/tex">\epsilon ^2</script>和<script type="math/tex">N</script>，<script type="math/tex">\epsilon ^2</script>减小(要求降低)与<script type="math/tex">N</script>(样本增加)增大都能够使坏事情发生的概率的上限减少。当上限足够小的时候，我们可以说，sample中orange的比例和bin中orange的概率<strong>差不多</strong>，如果sample中的orange比例少，则bin中的orange的比例也会比较少。</p>
<p>&emsp;&emsp;我们可以把learning与抓球这件事结合起来。</p>
<p><img src="images/marble_learning.png" alt=""></p>
<p>&emsp;&emsp;还记得之前说过的<script type="math/tex">f</script>吗？他代表未知的真理，而<script type="math/tex">h(x)是</script>是属于hypothesis set <script type="math/tex">\mathcal{H}</script>的某一个方程。对于某一个向量<script type="math/tex">x_n</script>：</p>
<ul>
<li>如果<script type="math/tex">h(x_n)\neq f(x_n)</script>，即他们判断不一致，我们记第n个小球是orange</li>
<li>如果<script type="math/tex">h(x_n)=f(x_n)</script>, 即他们判断是一致的，我们记第n个小球是green</li>
</ul>
<p>&emsp;&emsp;利用之前抓小球的逻辑，我们可以利用sample中orange的比例来推断总体中orange出现的概率，则同样的，我们可以利用sample中<script type="math/tex">h(x)\neq f(x)</script>的比例来推断总体中<script type="math/tex">h(x)\neq f(x)</script>的概率。这里<script type="math/tex">h(x)\neq f(x)</script>表示一个error，则我们可以称 <script type="math/tex">h(x)</script> 在sample中出现error的比例为 <script type="math/tex">E\_{in}</script> (in-sample-error)，在总体中出现error的概率为 <script type="math/tex">E\_{out}</script> (out-of-sample-error)。则对于 <script type="math/tex">h</script> 来说：</p>
<ul>
<li><p><script type="math/tex">E_{out}(h) = \underset{x\sim P}{\epsilon} [h(x)\neq f(x)]</script>，<script type="math/tex">\epsilon</script>表示数学期望</p>
</li>
<li><p><script type="math/tex">E\_{in}(h) = \frac{1}{N}\sum\_{n=1} ^ {N}[h(x\_n)\neq y\_n]</script></p>
</li>
</ul>
<p>&emsp;&emsp;利用Hoeffding&#39;s Inequality，我们可以写成：</p>
<script type="math/tex; mode=display">\mathbb{P}[|E\_{in}(h)-E\_{out}(h)|\gt \epsilon]\leq 2 exp(-2\epsilon ^2N)</script><p>&emsp;&emsp;简单说来，当右边这个“上界”足够小时，我们可以说<script type="math/tex">h</script>在sample中的表现(错误率)与<script type="math/tex">h</script>在总体中的表现是差不多的。</p>
<p><img src="images/setup_of_the_learning_problem_add_components.png" alt=""></p>
<p>&emsp;&emsp;注意这里仅仅是说，对于一个固定的<script type="math/tex">h (fixed h)</script>而言，<script type="math/tex">E\_{in}(h)</script>会与<script type="math/tex">E\_{out}(h)</script>很接近，这种情况能说是一种好的learning吗？当然不能，因为如果<script type="math/tex">E\_{in}(h)</script>很大，则<script type="math/tex">E\_{out}</script>也大，这样是没有意义的。因此我们的算法<script type="math/tex">\mathcal{A}</script>要能够自由的从<script type="math/tex">\mathcal{H}</script>中挑选方程，我们把<script type="math/tex">\mathcal{A}</script>挑选出的最好的<script type="math/tex">h</script>称为<script type="math/tex">g</script> (final hypothesis)。因此这里就需要添加一个验证流程(Verification Flow)，这个流程使用历史数据来判断某个<script type="math/tex">h</script>够不够好。</p>
<p><img src="images/verification_flow.png" alt=""></p>
<h2 id="-bad-data">不幸的状况 (Bad Data)</h2>
<p>&emsp;&emsp;前面说到，<script type="math/tex">\mathcal{A}</script>要能够自由的在<script type="math/tex">\mathcal{H}</script>中挑选它认为最适合的方程，因此这个最适合的方程就有可能是<script type="math/tex">\mathcal{H}</script>中的任何一个，有可能是<script type="math/tex">h\_1</script>，有可能是<script type="math/tex">h\_2</script>，<script type="math/tex">\mathcal{H}</script>中任意一个<script type="math/tex">h</script>都有可能成为<script type="math/tex">g</script>。但我们知道，我们的<script type="math/tex">\mathcal{D}</script>只是来自于总体的一个样本 (sample)，既然是sample，就一定会存在抽样误差。譬如你想知道一枚硬币抛出正面的概率是多少，于是你扔了5次，有一定的可能你连续扔了5个正面出来，这时候说抛出正面的概率是1，这样对吗？这当然是行不通的，因此你扔的这5次硬币，就是一个<strong>bad sample</strong>。凡是由于抽样误差所造成样本分布与总体分布相差很大的样本，我们都可以称之为<strong>bad sample</strong>。</p>
<p>&emsp;&emsp;learning同样会遇到bad sample的麻烦。比如实际上<script type="math/tex">h\_1</script>是个很好的方程，本来能够成为<script type="math/tex">g</script>的，但是由于抽样误差，碰到了bad sample，造成<script type="math/tex">E\_{in}(h\_1)</script>很大，<script type="math/tex">\mathcal{A}</script>最终没有选择它。又比如<script type="math/tex">h\_2</script>是个不好的方程，碰到了bad sample，碰巧<script type="math/tex">E\_{in}(h\_2)</script>又很小，导致<script type="math/tex">\mathcal{A}</script>错误得选择了它作为<script type="math/tex">g</script>。因此每个<script type="math/tex">h</script>都有可能遇上bad sample的烦恼。对于任意一个<script type="math/tex">h</script>来说，bad sample会造成他们的<script type="math/tex">| E\_{in}(h) - E\_{out}(h) | > \epsilon</script>。</p>
<p>&emsp;&emsp;因此只要<script type="math/tex">\mathcal{H}</script>中任意个<script type="math/tex">h</script>遇上bad sample，我们的<script type="math/tex">\mathcal{A}</script>在挑选方程时就会遇到麻烦，我们的learning就有可能不太好。那么bad sample发生的概率有多大呢？</p>
<script type="math/tex; mode=display">
\begin{aligned}
\ & \mathbb{P}_{\mathcal{D}}[BAD\ \mathcal{D}] \\\
\ & = \mathbb{P}_{\mathcal{D}}[BAD\ \mathcal{D}\ for\ h_1\ or\ BAD\ \mathcal{D}\ for\ h_2\ or\ ...\ or\ BAD\ \mathcal{D}\ for\ h_M]\\\
\ & \leq \mathbb{P}_{\mathcal{D}}[BAD\ \mathcal{D}\ for\ h_1] + \mathbb{P}_{\mathcal{D}}[BAD\ \mathcal{D}\ for\ h_2]+...+\mathbb{P}_{\mathcal{D}}[BAD\ \mathcal{D}\ for\ h_M] \\\
\ & \leq 2exp(-2\epsilon ^2N) + \leq 2exp(-2\epsilon ^2N) + ... + \leq 2exp(-2\epsilon ^2N) \\\
\ & = 2Mexp(-2\epsilon ^2N)
\end{aligned}
</script>

<p>&emsp;&emsp;由此看出，learning得好不好，还与<script type="math/tex">\mathcal{H}</script>里面的方程数量<script type="math/tex">M</script>有关。当<script type="math/tex">M</script>是有限的时候，数据量越大，发生bad sample的可能性越低。同理如果<script type="math/tex">M</script>太大，我们也越容易遇到bad sample。</p>
<h2 id="-summary">总结 (Summary)</h2>
<p>&emsp;&emsp;从概率论的角度出发，可以证明learning的确是可行的。因此，只有当<script type="math/tex">E\_{in}(h)</script>和<script type="math/tex">E\_{out}(h)</script>的判断很接近的时候，我们才能说learning是可行的。可行之余，倘若<script type="math/tex">E\_{in}(h)</script>很大，这样的learning也没有太大意义，因为你的这个<script type="math/tex">h</script>在sample中表现不好，则他在out-of-sample中表现也不大可能会好。我们把<script type="math/tex">\mathcal{H}</script>中表现最好(<script type="math/tex">E\_{in}</script>最低)的那个方程选出来，记为<script type="math/tex">g</script>。当然如何定义“最好”，以及如何去寻找“最好”，则是后面的内容。</p>

                    
                    </section>
                
                </div>
            </div>
        </div>

        
        <a href="../section2/README.html" class="navigation navigation-prev " aria-label="Previous page: Why Can Machines Learn?"><i class="fa fa-angle-left"></i></a>
        
        
        <a href="../section2/vc-dimension-one.html" class="navigation navigation-next " aria-label="Next page: VC Dimension Part I"><i class="fa fa-angle-right"></i></a>
        
    </div>
</div>

        
<script src="../gitbook/jsrepl/jsrepl.js" id="jsrepl-script"></script>
<script src="../gitbook/app.js"></script>

    
    <script src="../gitbook/plugins/gitbook-plugin-disqus/plugin.js"></script>
    

    
    <script src="https://cdn.mathjax.org/mathjax/2.0-latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    

    
    <script src="../gitbook/plugins/gitbook-plugin-mathjax/plugin.js"></script>
    

<script>
require(["gitbook"], function(gitbook) {
    var config = {"disqus":{"shortName":"mlnotebook"}};
    gitbook.start(config);
});
</script>

        
    </body>
    
</html>
